{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/gal/.pyenv/versions/3.8.10/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/gal/.pyenv/versions/3.8.10/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "data_file = \"sample_datasets/small_sequences.fasta\"\n",
    "processed_output_directory = \"full_datasets/preprocessed/small_sequences/\"\n",
    "codon_input_length = 5 # number of codons to input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToMultiDimArray(st):\n",
    "    helper_stack = deque()\n",
    "    for ch in st:\n",
    "        if ch == '[':\n",
    "            helper_stack.append([])\n",
    "        elif ch == ']':\n",
    "            current = helper_stack.pop()\n",
    "            if len(helper_stack) > 0:\n",
    "                helper_stack[-1].append(current)\n",
    "            else:\n",
    "                helper_stack.append(current)\n",
    "        elif ch not in [' ', ',']:\n",
    "            helper_stack[-1].append(int(ch))\n",
    "    return helper_stack[0]\n",
    "\n",
    "\n",
    "def parseSample(directory, id):\n",
    "    sample_x_file_st = directory + str(id) + \"_x.txt\"\n",
    "    sample_y_file_st = directory + str(id) + \"_y.txt\"\n",
    "    sample_x_file = open(sample_x_file_st, 'r')\n",
    "    sample_y_file = open(sample_y_file_st, 'r')\n",
    "    sample_x_st = sample_x_file.read()\n",
    "    sample_y_st = sample_y_file.read()\n",
    "    sample_x = stringToMultiDimArray(sample_x_st)\n",
    "    sample_y = stringToMultiDimArray(sample_y_st)\n",
    "    print(np.array([sample_x]))\n",
    "    return (sample_x, sample_y)\n",
    "\n",
    "def epochGenerator(directory):\n",
    "    def helper():\n",
    "        files = os.listdir(directory)\n",
    "        samples = len(files) // 2\n",
    "        for i in range(samples):\n",
    "            (x, y) = parseSample(directory, i)\n",
    "            return (np.array([x]), np.array([y]))\n",
    "            # return (np.array([x]), np.array([]))\n",
    "    return helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 5, 10)             3000      \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 5)                 320       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               768       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,344\n",
      "Trainable params: 12,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 01:29:39.726229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-22 01:29:40.515585: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.515712: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.515789: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11730 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.515821: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7246 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.519465: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.519603: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.519671: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11730 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.519728: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7246 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.523432: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.523681: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.523974: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11730 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.524164: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7246 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.529547: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.529724: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.529795: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11730 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.529840: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7246 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.535908: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.536038: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 01:29:40.536095: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11730 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.536131: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7246 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n",
      "2023-05-22 01:29:40.573086: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at partitioned_function_ops.cc:115 : INVALID_ARGUMENT: No OpKernel was registered to support Op 'CudnnRNN' used by {{node CudnnRNN}} with these attrs: [direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=0, is_training=true, seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\"]\n",
      "Registered devices: [CPU, GPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[CudnnRNN]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nNo OpKernel was registered to support Op 'CudnnRNN' used by {{node CudnnRNN}} with these attrs: [direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=0, is_training=true, seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[CudnnRNN]]\n\t [[sequential_18/lstm_36/PartitionedCall]] [Op:__inference_train_function_73505]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mfit(DataGenerator(processed_output_directory))\n\u001b[1;32m     15\u001b[0m \u001b[39m# inputs = tf.keras.layers.Input(shape=(1,))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# predictions = tf.keras.layers.Dense(1)(inputs)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# model.compile(loss='mse',\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#               optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tfdml_plugin/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tfdml_plugin/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nNo OpKernel was registered to support Op 'CudnnRNN' used by {{node CudnnRNN}} with these attrs: [direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=0, is_training=true, seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[CudnnRNN]]\n\t [[sequential_18/lstm_36/PartitionedCall]] [Op:__inference_train_function_73505]"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "# strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "# with strategy.scope():\n",
    "with tf.device('/GPU:1'):\n",
    "  tf.debugging.set_log_device_placement(True)\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(10, input_shape=(5, 64), return_sequences=True))\n",
    "  model.add(LSTM(5, return_sequences=False))\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dense(64, activation='softmax'))\n",
    "  model.summary()\n",
    "  # model\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  model.fit(DataGenerator(processed_output_directory))\n",
    "  # inputs = tf.keras.layers.Input(shape=(1,))\n",
    "  # predictions = tf.keras.layers.Dense(1)(inputs)\n",
    "  # model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "  # model.compile(loss='mse',\n",
    "  #               optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
